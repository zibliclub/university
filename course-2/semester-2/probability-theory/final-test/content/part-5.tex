\section{Функция распределения случайного вектора}

\begin{definition}[Распределение случайного вектора]
	Пусть $\xi $ -- случайный вектор. Функция
	\[
		P_{\xi } (B) = P \big(\xi^{-1} (B)\big)
	\]
	называется \emph{распределением $\xi $},
	\[
		F_{\xi } (x_1,\ldots ,x_n) = P(\xi _1 < x_1, \ldots , \xi _n < x_n)
	\]
	называется \emph{функцией распределения} $\xi $.
\end{definition}

\newpage

\section{Плотность распределения случайного вектора}

\begin{definition}[Плотность распределения случайного вектора]
	\emph{Плотностью распределения случайного вектора} $\xi $ называется
	\[
		P(\xi \in B) = \underset{B}{\int \ldots \int} P_{\xi } (x_1,\ldots ,x_n)\d x_1 \ldots \d x_n.
	\]
\end{definition}

\section{Независимые классы событий}

\begin{definition}[Независимые классы событий]
	Пусть $\{A\}$ и $\{B\}$ -- два класса событий в вероятностном пространстве $(\Omega , \mathcal{F}, P)$. Эти классы называются \emph{независимыми}, если для любых событий $a \in A, \ b \in B$ выполняется:
	\[
		P(A \cap B) = P(A)\cdot P(B).
	\]

	Другими словами, каждое событие из класса $A$ независимо от каждого события из класса $B$.
\end{definition}

\section{Теорема о независимости сигма-алебр}

\begin{theorem}
	Пусть $(\Omega , \mathcal{F}, P)$ -- вероятностное пространство, и пусть $G_1, \ G_2$ -- две под-$\sigma $-алгебры $\sigma $-алгебры $F$. Эти $\sigma $-алгебры называются \emph{независимыми}, если для любых событий $A \in G_1$ и $B \in G_2$ выполняется:
	\[
		P(A \cap B) = P(A) \cdot P(B).
	\]
\end{theorem}

\section{Независимые случайные величины}

\begin{definition}[Независимые случайные величины]
	Случайные величины $\xi , \eta$ называются \emph{независимыми}, если $\forall \alpha ,\beta \in \R$ события $[\xi \leqslant \alpha ], \ [\eta \leqslant \beta ]$ независимы,
	\[
		P \big((\xi \leqslant \alpha ) \cap (\eta \leqslant \beta )\big) = P(\xi \leqslant \alpha ) \cdot P(\eta \leqslant \beta ).
	\]
\end{definition}

\newpage

\section{Критерий независимости случайных величин в терминах функций распределения}

\begin{theorem}
	Пусть $X$ и $Y$ -- две случайные величины, заданные на одном и том же вероятностном пространстве $(\Omega ,\mathcal{F},P)$. Случайные величины $X$ и $Y$ называются независимыми, если их совместная функция распределения $F_{X,Y} (x,y)$ может быть представлена в виде произведения их маргинальных функций распределения $F_X(x)$ и $F_Y(y)$, то есть:
	\[
		F_{X,Y} (x,y) = F_X(x) \cdot F_Y (y) \qquad \forall x,y \in \R.
	\]
\end{theorem}

\section{Критерий независимости дискретных случайных величин}

\begin{theorem}
	Пусть $X,Y$ -- дискретные случайные величины, заданные на одном и том же вероятностном пространстве $(\Omega ,\mathcal{F},P)$. Случайные величины $X,Y$ называются независимыми, если для любых значений $x,y$ из их области определения совместная вероятность может быть представлена в виде произведения их маргинальных вероятностей, то есть:
	\[
		P(X=x,Y=y) = P(X=x) \cdot P(Y=y).
	\]
\end{theorem}

\section{Критерий независимости случайных величин в терминах плотностей распределения}

\begin{theorem}
	Пусть $X,Y$ -- две абсолютно непрерывные случайные величины, заданные на одном и том же вероятностном пространстве $(\Omega ,\mathcal{F},P)$. Пусть $P_{X,Y}(x,y)$ -- совместная плотность распределения случайных величин $X,Y$, а $P_X(x), \ P_Y(y)$ -- их маргинальные плотности распределения. Случайные величины $X,Y$ называются независимыми, если их совместная плотность распределения может быть представлена в виде произведения их маргинальных плотностей распределения, то есть:
	\[
		P_{X,Y} (x,y) = P_X(x)\cdot P_Y(y) \qquad \forall x,y \in \R.
	\]
\end{theorem}

\section{Формула для математического ожидания дискретной случайной величины}

\[
	M(X) = \sum_{i=1}^{n} x_ip_i.
\]

\section{Формула для математического ожидания абсолютно непрерывной случайной величины}

\[
	M(X) = \int_{-\infty }^{+\infty } x f(x) \d x.
\]
