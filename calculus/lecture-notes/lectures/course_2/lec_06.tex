\lesson{6}{от 28 сен 2023 8:48}{Продолжение}


\section*{Достаточное условие условного локального экстремума}

\begin{note}
    Пусть $f:D\rightarrow\R, \ D \subset \R^n$ -- область, $f \in C^{(2)} (D,\R), \ S$ -- $(n-k)$-мерная поверхность в $D$, заданная системой уравнений:
    \[
        \left\{\begin{array}{l}
            F^1(x^1,\ldots,x^n) = 0 \\
            \vdots                  \\
            F^k(x^1,\ldots,x^n) = 0
        \end{array}\right..
    \]

    Функция Лагранжа:
    \[
        L(x,\lambda) = f(x^1,\ldots,x^n) + \sum_{i = 0}^{k}\lambda_i \cdot F^i(x^1,\ldots,x^n).
    \]

    Здесь $\lambda_1,\ldots,\lambda_k$ выбираются таким образом, чтобы было выполнено необходимое условие условного экстремума в точке $x_0$ (\ref{eq:24}).
    \[
        \left\{\begin{array}{l}
            \frac{\delta L}{\delta x^i} = 0 \\
            \vdots                          \\
            \frac{\delta L}{\delta \lambda_j} = 0
        \end{array}\right. \implies x_0,\quad \lambda_1,\ldots,\lambda_k.
    \]
\end{note}

\begin{theorem}[Достаточное условие условного экстремума]
    Если при введенных выше условиях квадратичная форма
    \[
        Q(\xi) = \sum_{i,j=1}^{n}\frac{\delta^2 L}{\delta x^i \delta x^j}(x_0)\cdot\xi^i\xi^j,\ \big(\xi=(\xi^1,\ldots,\xi^n)\big)
    \]
    \begin{enumerate}
        \item Знакоопределена на $TS_{x_0}$:
              \begin{itemize}
                  \item если $Q$ знакоположительна, то точка $x_0$ -- точка условного локального $\min$
                  \item если $Q$ знакоотрицательна, то точка $x_0$ -- точка условного локального $\max$
              \end{itemize}
        \item Если $Q$ может принимать значения разных знаков, то в точке $x_0$ условного экстремума не наблюдается.
    \end{enumerate}
\end{theorem}

\begin{proof}
    Заметим, что $f\big|_S$ и $L\big|_S$ совпадают. В самом деле, если $x\in S$, то:
    \[
        L(x,\lambda) = f(\equalto{x}{(x^1,\ldots,x^n)}) + \sum_{i=1}^{k}\lambda_i\cdot \equalto{F^i(x)}{0} = f(x).
    \]

    Поэтому покажем, что условие знакопостоянства $Q$ является достаточным для экстремума функции $L\big|_s$.

    Имеем, что
    \[
        \left\{\begin{array}{l}
            \frac{\delta L}{\delta x^1}(x_0) = 0 \\
            \vdots                               \\
            \frac{\delta L}{\delta x^n}(x_0) = 0
        \end{array}\right..
    \]

    По формуле Тейлора:
    \begin{equation}\label{eq:25}
        L\big|_S(x) - L(x_0) = \sum_{i,j=1}^{n}\frac{\delta^2 L(x_0)}{\delta x^i \delta x^j}\cdot(x^i - x_0^i)(x^j - x_0^j) + o\big(\|x-x_0\|^2\big)
    \end{equation}

    Так как $S$ -- $m=(n-k)$-мерная поверхность, то существует гладкое отображение $x(t):\R^m\rightarrow\R^n: \ x = x(t) \subset S \ \forall t \in \R^m, \ x(0) = x_0$. Отображение $x(t)$ биективно отображает $\R^m$ на $U_S(x_0) = U(x_0)\cap S$.

    Если $x\in S$, то условие дифференцируемости $x(t)$:
    \[
        x-x_0 = x(\underset{\in\R^m}{t}) - x(0) = x'(0)\cdot t + o\big(\|t\|\big)
    \]
    \begin{center}
        или
    \end{center}
    \[
        \left\{\begin{array}{l}
            x^1 - x^1_0 = \frac{\delta x^1}{\delta t^1}(0)\cdot t^1 + \ldots + \frac{\delta x^1}{\delta t^m}(0)\cdot t^m + o\big(\|t\|\big) \\
            \vdots                                                                                                                          \\
            x^n - x^n_0 = \frac{\delta x^n}{\delta t^1}(0)\cdot t^1 + \ldots + \frac{\delta x^n}{\delta t^m}(0)\cdot t^m + o\big(\|t\|\big) \\
        \end{array}\right.
    \]
    \begin{center}
        или кратко
    \end{center}
    \begin{equation}\label{eq:26}
        \left\{\begin{array}{l}
            x^1 - x^1_0 = \sum_{i=1}^{m}\frac{\delta x^1}{\delta t^i}(0)\cdot t^i + o\big(\|t\|\big) \\
            \vdots                                                                                   \\
            x^n - x^n_0 = \sum_{i=1}^{m}\frac{\delta x^n}{\delta t^i}(0)\cdot t^i + o\big(\|t\|\big) \\
        \end{array}\right.
    \end{equation}

    Подставим \ref{eq:26} в \ref{eq:25}:
    \begin{multline*}
        L\big|_S(x) - L(x_0) = \frac{1}{2}\cdot\sum_{i,j=1}^{n}\frac{\delta^2L(x_0)}{\delta x^i \delta x^j} \cdot \underbrace{\left(\sum_{\alpha=1}^{m}\frac{\delta x^i}{\delta t^\alpha}(0)\cdot t^\alpha + o\big(\|t\|\big)\right)}_{x^i - x_0^i}\cdot \\
        \cdot \underbrace{\left(\sum_{\beta=1}^{m}\frac{\delta x^j}{\delta t^\beta}(0)\cdot t^\beta + o\big(\|t\|\big)\right)}_{x^j - x_0^j} + o\big(\|x-x_0\|^2\big) = \\
        = \frac{1}{2}\sum_{i,j=1}^{n}\frac{\delta^2 L(x_0)}{\delta x^i \delta x^j}\cdot\Bigg[\left(\sum_{\alpha=1}^{m}\frac{\delta x^i}{\delta t^\alpha}(0)\cdot t^\alpha\right)\cdot\left(\sum_{\beta=1}^{m}\frac{\delta x^i}{\delta t^\beta}(0)\cdot t^\beta\right) + \\
            + \left(\sum_{\alpha=1}^{m}\frac{\delta x^i}{\delta t^\alpha}(0)\cdot t^\alpha\right)\cdot o\big(\|t\|\big) + \left(\sum_{\beta=1}^{m}\frac{\delta x^i}{\delta t^\beta}(0)\cdot t^\beta\right)\cdot \\
            \cdot o\big(\|t\|\big) + o\big(\|t\|\big)\Bigg] + o\big(\|x-x_0\|^2\big) \overset{(\heartsuit)}{=} \frac{1}{2}\sum_{i,j=1}^{n}\frac{\delta^2 L(x_0)}{\delta x^i \delta x^j} \cdot \\
        \cdot \sum_{\alpha,\beta = 1}^{m}\frac{\delta x^i}{\delta t^\alpha} \cdot \frac{x^i}{\delta t^\beta} \cdot t^\alpha \cdot t^\beta + o\big(\|t\|^2\big) = \frac{\|t\|^2}{2} \cdot \sum_{i,j=1}^{n}\frac{\delta^2 L(x_0)}{\delta x^i\delta x^j} \cdot \\
        \cdot \underbrace{\sum_{\alpha,\beta=1}^{m}\frac{\delta x^i}{\delta t^\alpha}\cdot \frac{\delta x^j}{\delta t^\beta} \cdot \frac{t^\alpha}{\|t\|} \cdot \frac{t^\beta}{\|t\|}}_{\xi^i,\xi^j\text{ -- координаты вектора }\xi\in TS_{x_0}} + o\big(\|t\|^2\big) = \frac{\|t\|^2}{2}Q(\xi) + o\big(\|t\|^2\big).
    \end{multline*}

    Таким образом получаем, что
    \[
        L\big|_S(x) - L(x_0) = \frac{\|t\|^2}{2} \cdot Q(\xi) + o\big(\|t\|^2\big), \ \xi \in TS_{x_0}.
    \]

    Тогда, если $Q> 0$, то
    \[
        L\big|_S(x) - L(x_0)> 0 \implies x_0 \text{ -- } \min \text{ для } L\big|_S(x) \implies x_0 \text{ -- } \min \text{ для } f\big|_S.
    \]

    Если $Q < 0$, то
    \[
        L\big|_S(x) - L(x_0) < 0 \implies x_0 \text{ -- локальный } \max \text{ для } L\big|_S(x) \implies
    \]
    \[
        \implies x_0 \text{ -- локальный } \max \text{ для } f\big|_S \ (\forall x \in U_S(x_0))
    \]

    Если $Q$ -- знакопеременна, то не для всех $x \in U_S(x_0)$ разность $L\big|_S(x) - L(x_0)$ имеет постоянный знак $\implies$ в этом случае в точке $x_0$ нет экстремума.

    Докажем $(\heartsuit)$, то есть покажем, что
    \[
        o\big(\|t\|\big) \cdot \sum_{\alpha = 1}^{m} \frac{\delta x^i}{\delta t^\alpha}\cdot t^\alpha = o\big(\|t\|^2\big)
    \]
    \begin{center}
        и
    \end{center}
    \[
        o\big(\|x-x_0\|^2\big) = o\big(\|t\|^2\big), \ x \in S.
    \]

    В самом деле,
    \[
        \left| \sum_{\alpha=1}^{m}\frac{\delta x^i}{\delta t^\alpha}(0)\cdot t^\alpha\right| \leqslant \sum_{\alpha=1}^{m}\left|\frac{\delta x^i}{\delta t^\alpha}(0)\right| \cdot \big|t^\alpha \big| \leqslant \|t\| \cdot \equalto{\underbrace{\sum_{\alpha = 1}^{m} \left|\frac{\delta x^i}{\delta t^\alpha}(0)\right|}}{const>0} = \equalto{\underbrace{\overset{>0}{A}\cdot \|t\|}}{O\big(\|t\|\big)}.
    \]

    Таким образом,
    \begin{multline*}
        o\big(\|t\|\big) \cdot \bigg|\sum_{\alpha = 1}^{m}\frac{\delta x^i(0)}{\delta t^\alpha}\cdot t^\alpha \bigg| \leqslant o\big(\|t\|\big)\cdot O\big(\|t\|\big) = \\
        = \omega(t)\cdot \|t\| \cdot \gamma(t) \cdot \|t\| = \left|\begin{array}{c}
            \text{где }\omega(t)\rightarrow0 \text{ при } t\rightarrow 0, \\
            \gamma(t)\text{ -- ограниченная функция}
        \end{array}\right| = \\
        = \equalto{\alpha(t)}{\omega(t)\gamma(t)} \cdot \|t\|^2 = o\big(\|t\|^2\big), \begin{array}{l}
            \alpha(t)\rightarrow 0, \\
            t\rightarrow 0
        \end{array}.
    \end{multline*}

    Далее, если $x\in S$, то
    \begin{multline*}
        \|x-x_0\|^2 = \left\|\left(\begin{matrix}
                x^1 - x_0^1 \\
                \vdots      \\
                x^n - x^n_0
            \end{matrix}\right)\right\|^2 \overset{\text{\ref{eq:26}}}{=} \left\|\left(\begin{matrix}
                \sum_{\alpha=1}^{m}\frac{\delta x^1}{\delta t^\alpha}\cdot t^\alpha + o\big(\|t\|\big) \\
                \vdots                                                                                 \\
                \sum_{\alpha=1}^{m}\frac{\delta x^n}{\delta t^\alpha}\cdot t^\alpha + o\big(\|t\|\big)
            \end{matrix}\right)\right\|^2 = \\
        = \left(\sum_{\alpha = 1}^{m}\frac{\delta x^1}{\delta t^\alpha}\cdot t^\alpha + o\big(\|t\|\big)\right)^2 + \ldots + \left(\sum_{\alpha=1}^{m}\frac{\delta x^n}{\delta t^\alpha} + o\big(\|t\|\big)\right)^2 =\\
        = \left(\sum_{\alpha = 1}^{m}\frac{\delta x^1}{\delta t^\alpha}\cdot t^\alpha \right)^2 + \ldots + \left(\sum_{\alpha=1}^{m}\frac{\delta x^n}{\delta t^\alpha} \right)^2 + o\big(\|t\|^2\big) \leqslant \\
        \leqslant \left( \underset{\alpha}{\max}\frac{\delta x^1}{\delta t^\alpha}\right)^2 \cdot \left(\sum_{\alpha=1}^{m} t^\alpha\right)^2 + \ldots + \left(\underset{\alpha}{\max}\frac{\delta x^n}{\delta t^\alpha}\right)^2\cdot\left(\sum_{\alpha=1}^{m}t^\alpha\right)^2 \leqslant \\
        \leqslant \|t\|^2 \cdot \left(\left(\underset{\alpha}{\max}\frac{\delta x^1}{\delta t^\alpha}\right)^2 + \left(\max \frac{\delta x^n}{\delta t^\alpha}\right)^2\right) \leqslant \\
        \leqslant \|t\|^2 \cdot \equalto{\underbrace{\left(\underset{i}{\max}\left(\underset{\alpha}{\max}\frac{\delta x^i}{\delta t^\alpha}(0)\right)\right)^2 \cdot n}}{const>0} = B\|t\|^2 = o\big(\|t\|^2\big).
    \end{multline*}

    Поэтому
    \begin{multline*}
        o\big(\|x-x_0\|^2\big) = \\
        = \beta(x-x_0)\cdot \|x-x_0\|^2 = \beta(t)\cdot \|x-x_0\|^2 \leqslant \beta(t) \cdot B \cdot \|t\|^2 = \\
        = o\big(\|t\|^2\big)
    \end{multline*}
    \[
        \big(\beta(x-x_0)\rightarrow0\text{ при }x \rightarrow x_0 \iff t \rightarrow 0\big)
    \]
\end{proof}

\chapter{Теория рядов}

\section{Введение}

\begin{definition}[Ряд]
    \emph{Рядом} называется выражение:
    \[
        a_1 + a_2 + \ldots + a_n + \ldots, \quad a_i \in \R.
    \]

    Числа $ a_i $ называются \emph{членами ряда}, $ a_n $ -- \emph{$ n $-ым членом ряда}.

    \begin{equation}\label{eq:6.1}
        \sum_{n=1}^{\infty}a_n
    \end{equation}

    Рассмотрим числа:
    \begin{align*}
         & A_1 = a_1,                      \\
         & A_2 = a_1 + a_2,                \\
         & \vdots                          \\
         & A_n = a_1 + a_2 + \ldots + a_n.
    \end{align*}

    Числа $ A_1,A_2,\ldots,A_n $ называются \emph{частичными суммами ряда} \ref{eq:6.1}.
\end{definition}

\begin{definition}[Сходящийся ряд]
    Говорят, что ряд \ref{eq:6.1} \emph{сходится}, если существует конечный предел частичных сумм, то есть
    \[
        \exists \underset{n\rightarrow\infty}{\lim}A_n = A.
    \]

    Тогда сумма бесконечного ряда \ref{eq:6.1} полагается равной
    \[
        A = \sum_{n=1}^{\infty}a_n.
    \]
\end{definition}

\newpage

\begin{example}
    \[
        10 + 1 + \frac{1}{10} + \frac{1}{10^2} + \ldots + \frac{1}{10^n} + \ldots = 10 + \sum_{k=0}^{\infty}\frac{1}{10^k}
    \]
    \begin{multline*}
        A_n = \frac{1}{10^0} + \frac{1}{10^1} + \ldots + \frac{1}{10^n} = \frac{1\cdot(q^n - 1)}{q - 1} = \\
        = \frac{\frac{1}{10^n} - 1}{\frac{1}{10} - 1} = \frac{1 - \frac{1}{10^n}}{\frac{9}{10}} = \frac{10}{9} \cdot \left(1 - \frac{1}{10^n}\right)
    \end{multline*}
    \[
        \underset{n\rightarrow\infty}{\lim}A_n = \underset{n\rightarrow\infty}{\lim}\frac{10}{9}\left(1-\frac{1}{10^n}\right) = \frac{10}{9}
    \]
\end{example}

\subsection{Гармонический ряд}

\begin{definition}[Cреднее гармоническое]
    Число $c$ называется \emph{средним гармоническим} чисел $a$ и $b$ ($a,b \ne 0$), если
    \[
        \frac{1}{c} = \frac{1}{2}\cdot \left(\frac{1}{a} + \frac{1}{b}\right).
    \]
\end{definition}

\begin{definition}[Гармонический ряд]
    Ряд вида
    \begin{equation}\label{eq:6.2}
        \sum_{n=1}^{\infty}\frac{1}{n}
    \end{equation}
    называется \emph{гармоническим}.
\end{definition}

\begin{note}
    Докажем, что ряд \ref{eq:6.2} расходится.

    Если $\exists\epsilon > 0 \ \forall N \ \exists n > N \ \exists p > 0$
    \[
        |a_{n+1} + \ldots + a_{n+p}| \geqslant \epsilon
    \]
    \begin{multline*}
        \left|\frac{1}{n+1} + \frac{1}{n+2} + \ldots + \frac{1}{n+p}\right| \geqslant \left|\frac{1}{n+p} + \frac{1}{n+p} + \ldots + \frac{1}{n+p}\right| = \\
        = \frac{p}{n+p} \underset{n = p}{=} \frac{1}{2},
    \end{multline*}
    то есть для $\forall N: \ \epsilon = \frac{1}{2}, \ p = n, \ n = N + 1 \implies$ по критерию Коши, гармонический ряд \ref{eq:6.2} расходится.
\end{note}

\newpage

\subsection{Основные свойства сходящихся рядов}

\begin{theorem}[Критерий Коши]
    Ряд \ref{eq:6.1} сходится тогда и только тогда, когда $\forall \epsilon > 0 \ \exists N \in \mathbb{N}: \ \forall n > N, \ \forall p > 0$
    \[
        |a_{n+1} + \ldots + a_{n+p}| < \epsilon.
    \]
\end{theorem}

\begin{proof}
    Ряд \ref{eq:6.1} сходится $\underset{\text{по определению}}{\iff} \exists \underset{n\rightarrow\infty}{\lim}A_n \iff A_n$ -- фундаментальная последовательность: $\forall \epsilon > 0 \ \exists N \in \mathbb{N}: \ \forall n > N$ и $\forall p > 0$
    \[
        |A_n - A_{n+p}| < \epsilon, \quad \left(\begin{array}{c}
                \text{критерий Коши сходимости} \\
                \text{последовательности}
            \end{array}\right).
    \]
    Имеем
    \begin{multline*}
        |A_n - A_{n+p}| = \\
        =\big|a_1 + a_2 + \ldots + a_n - (a_1 + a_2 + \ldots + a_n + \ldots + a_{n+p})\big| = \\
        = |a_{n+1} + \ldots + a_{n+p}| < \epsilon.
    \end{multline*}
\end{proof}

\begin{remark}
    Со всякой последовательностью $x_n$ можно связать ряд, частичными суммами которого являются члены этой последовательности. Пусть:
    \[
        x_1,x_2,\ldots,x_n,\ldots.
    \]

    Тогда ряд
    \[
        \underbrace{x_1}_{a_1} + \underbrace{(x_2 - x_1)}_{a_2} + \underbrace{(x_3 - x_2)}_{a_3} + \ldots + \underbrace{(x_n - x_{n-1})}_{a_n} + \ldots,
    \]
    \[
        A_n = a_1 + \ldots + a_n = x_1 + (x_2 - x_1) + \ldots + (x_n - x_{n-1}) = x_n.
    \]
\end{remark}

\begin{theorem}[Необходимое условие сходимости ряда]
    Если ряд \ref{eq:6.1} сходится, тогда:
    \[
        \underset{n\rightarrow\infty}{\lim}a_n = 0.
    \]
\end{theorem}

\begin{proof}
    Пусть ряд \ref{eq:6.1} сходится, тогда $\exists \underset{n\rightarrow\infty}{\lim}A_n$:
    \begin{eqnarray*}
        \underset{n\rightarrow\infty}{\lim}a_n &=& \underset{n\rightarrow\infty}{\lim}(A_n - A_{n-1}) = \\
        = \underset{n\rightarrow\infty}{\lim}A_n - \underset{n\rightarrow\infty}{\lim}A_{n-1} &=& 0
    \end{eqnarray*}
\end{proof}

\newpage